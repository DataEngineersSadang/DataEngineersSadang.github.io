---
title: 아파치 카프카란?
date: "2023-01-28T21:29:00.000Z"
tags:
  - JK
  - apache kafka
---

# 아파치 카프카, 왜 개발되었나?

최초 단방향 소스 app과 타겟 app에서 점차 소스, 타겟이 증가하고 양방향화되면서 데이터 전송라인의 복잡도가 증가하게 됨.

- 배포, 유지보수의 어려움 발생
- 프로토콜 포맷 산재

이러한 복잡함을 해결하기 위해 링크드인에서 개발하였음

- 낮은 지연(low latency) 높은 처리량으로 효율적인 대규모 처리
- TPCP 기반 프로토콜
- Pub/Sub 모델
- 고가용성
  - 서버 이슈 상황에서도 데이터의 손실을 방지
- 확장성
- 분산처리
- 디스크 순차 저장 및 처리

# 아파치 카프카의 특징

<!-- 카프카는 Source Application을 담당하는 Kafka Producer, 메시지를 저장하는 Broker, Target Application을 담당하는 Kafka Consumer로 구성된다.

이때 메시지 저장하는 Broker에는 Topic이라는 Queue와 유사한 개념이 있다. -->

## Kafka Topic

데이터의 저장 공간이라 볼 수 있다.

Kafka Topic은 일반적인 \*AMQP와는 다르게 동작한다.

하나의 토픽은 여러 파티션을 가질 수 있다.

### Topic의 동작 원리

#### 하나의 파티션(single partion)

- 파티션은 0번부터 시작하며, 프로듀서로부터 데이터를 전송받을 때 파티션에 0번부터 차곡차곡 쌓이게 된다.
- 컨슈머는 파티션의 0번 데이터(가장 오래된 데이터)부터 순서대로 추출한다.
- 이때, 파티션에서는 컨슈머가 데이터를 가져가더라도 데이터는 삭제되지 않는다.
  - 새로운 컨슈머(그룹)가 생길 때 가져가게 되는데, 단, `auto.offset.reset` 옵션이 `earliest`으로 설정되어야 한다.

#### 둘 이상의 파티션(multi partion)

- 키가 null 이고, 기본 파티셔너를 사용할 경우 라운드 로빈(Round robin)으로 할당
  > 라운드 로빈:
  -
- 키가 있고, 기본 파티셔너를 사용할 경우, 키의 해시(hash)값을 구하고, 특정 파티션에 할당
  - 해시값으로 할당?

#### 유의사항

파티션을 늘리면 컨슈머의 갯수를 데이터 처리를 분산시킬 수 있다. 하지만, 파티션을 늘릴 수는 있지만 줄일 수는 없기 때문에 주의해야한다.
(왜 늘리는 것에 유의해야할까?)

#### 파티션의 record는 언제 삭제되는가?

레코드가 저장되는 최대 시간과 크기에 대한 옵션에 따라 보관 및 삭제 관리할 수 있다.

- `log.retention.ms`: 최대 record 보존 시간
- `log.retention.byte`: 최대 record 보존 크기(byte)

## Broker, Replication, ISR 카프카(Kafka) 핵심요소!
