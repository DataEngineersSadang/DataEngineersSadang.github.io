---
title: Apache Kafka 훑어보기
date: "2023-01-28T21:29:00.000Z"
tags:
  - JK
  - apache kafka
---

# 아파치 카프카, 왜 개발되었나?

최초 단방향 소스 app과 타겟 app에서 점차 소스, 타겟이 증가하고 양방향화되면서 데이터 전송라인의 복잡도가 증가하게 됨.

- 배포, 유지보수의 어려움 발생
- 프로토콜 포맷 산재

이러한 복잡함을 해결하기 위해 링크드인에서 개발하였음

- 낮은 지연(low latency) 높은 처리량으로 효율적인 대규모 처리
- TPCP 기반 프로토콜
- Pub/Sub 모델
- 고가용성
  - 서버 이슈 상황에서도 데이터의 손실을 방지
- 확장성
- 분산처리
- 디스크 순차 저장 및 처리

# 아파치 카프카의 특징

카프카에는 Source Application을 담당하는 Kafka Producer, 메시지를 저장하는 카프카 서버 단위의 Broker, Target Application을 담당하는 Kafka Consumer의 개념이 있다.

이때 메시지 저장하는 Broker에는 Topic이라는 Queue와 유사한 개념이 있다.

## Kafka Topic

데이터의 저장 공간이라 볼 수 있다.

Kafka Topic은 일반적인 \*AMQP와는 다르게 동작한다.

하나의 토픽은 여러 파티션을 가질 수 있다.

### Topic의 동작 원리

#### 파티셔너

- 파티셔너는 프로듀서에서 레코드를 토픽의 어떤 파티션에 넣을지 결정하는 역할을 수행

- 레코드에 포함된 메시지 키 또는 메시지 값에 따라 파티션 위치가 결정
- 프로듀서에서 파티셔너를 따로 설정하지 않으면, `UniformStickyPartitioner`로 설정됨
  - 메시지 키가 있을 때 없을때 다르게 동작
    - 메시지 키가 있는 경우: hash 로직에 따라 메시지 키를 넣을 파티션 설정
      - 메시지 키에 따라 동일한 hash를 만들기 때문에, 항상 같은 파티션에 저장이 보장됨
      - 순서를 지키며 데이터를 처리할 수 있는 장점이 있음
    - 메시지 키가 없는 경우: 라운드로빈(Round Robin) 방식
      - `UniformStickyPartitioner`는 프로듀서에서 배치로 모을 수 있는 최대한의 레코드를 파티션으로 전송
      - 전통적인 라운드로빈과는 조금 다르게, 배치단위로 라운드로빈 형식으로 저장
- 커스텀 파티셔너를 만들 수 있도록 `Partitioner 인터페이스`를 제공
  - 커스텀 파티셔너를 통해 메시지 키 또는 메시지 값 또는 토픽 이름에 따라 파티션 저장을 설정
  - AMQP 메시징 시스템에서 우선순위 큐를 만드는 것과 유사한 방식으로 커스텀도 가능
    - ex) 10대 파티션 중 8개의 파티션을 vip고객의 메시지를 처리하는 것으로 할당

#### 하나의 파티션(single partion)

- 파티션은 0번부터 시작하며, 프로듀서로부터 데이터를 전송받을 때 파티션에 0번부터 차곡차곡 쌓이게 된다.
- 컨슈머는 파티션의 0번 데이터(가장 오래된 데이터)부터 순서대로 추출한다.
- 이때, 파티션에서는 컨슈머가 데이터를 가져가더라도 데이터는 삭제되지 않는다.
  - 새로운 컨슈머(그룹)가 생길 때 가져가게 되는데, 단, `auto.offset.reset` 옵션이 `earliest`으로 설정되어야 한다.

#### 둘 이상의 파티션(multi partion)

- 키가 null 이고, 기본 파티셔너를 사용할 경우 라운드 로빈(Round robin)으로 할당
- 키가 있고, 기본 파티셔너를 사용할 경우, 키의 해시(hash)값을 구하고, 특정 파티션에 할당

#### 유의사항

파티션을 늘리면 컨슈머의 갯수를 데이터 처리를 분산시킬 수 있다. 하지만, 파티션을 늘릴 수는 있지만 줄일 수는 없기 때문에 주의해야한다.
(왜 늘리는 것에 유의해야할까?)

#### 파티션의 record는 언제 삭제되는가?

레코드가 저장되는 최대 시간과 크기에 대한 옵션에 따라 보관 및 삭제 관리할 수 있다.

- `log.retention.ms`: 최대 record 보존 시간
- `log.retention.byte`: 최대 record 보존 크기(byte)

# Broker, Replication, ISR 카프카(Kafka) 핵심요소!

카프카 운영에서 고가용성을 보장하는 매우 중요한 요소

- Broker

  - 카프카에서 브로커는 카프카가 설치되어 있는 서버단위
  - 보통 3개 이상의 브로커로 구성하여 사용하는 것을 권장

- Replication

  - 복제를 통해 클러스터에서 서버에 장애 발생시 카프카 가용성을 보장하는 방법
  - 파티션을 여러 브로커에 나누어 복제하여 저장함
  - 단 브로커의 갯수보다 replication은 클 수 없음.

- 파티션 1, replication 2

  - 브로커 3개 중 1대에 topic의 데이터가 저장
  - 파티션 설정 1, replication 설정 2라면, 2개의 브로커에 파티션이 생성됨
    - 원본 파티션(`Leader partition`) 1, 복제 파티션(`Follower partition`) 1이 생성됨
    - 원본, 복제 파티션을 합쳐서 `ISR(In-Sync-Replica)` 이라고 할 수 있음
  - 모종의 이유로 `Leader partition`이 죽게되면, `Follower partition`이 `Leader partition`을 승계함

## 리더 파티션(Leader partition), 팔로워 파티션(Follower partition)

- 리더 파티션: Producer로 부터 데이터를 전달 받는 주체

- Producer에는 `ack` 옵션을 통해 고가용성 유지
  - `ack`=0: 리더 파티션에 데이터를 전송하고 응답값을 받지 않음
    - 데이터 전송 및 복제 저장 유무를 파악하기 힘듦
    - 속도는 빠르지만, 데이터 유실의 가능성이 있음
  - `ack`=1: 리더 파티션에 데이터를 전송하고 리더 파티션이 데이터를 정상으로 받았는지 응답값을 받음
    - 데이터 전송 유무는 파악 가능하지만, 복제 저장 유무는 파악 불가
    - 리더 파티션이 데이터를 받은 즉시, 브로커가 장애가 난다면 데이터 유실
  - `ack`=all: 리더 파티션에 데이터를 전송하고 데이터의 전송 및 복제 저장 유무 응답값을 받음
    - 팔로워 파티션에 저장되는 부분까지도 응답값을 받음
    - 데이터 유실은 없다 볼 수 있지만, 응답값이 많기 때문에 속도면에서 느림

## replication 유의사항

- replication의 갯수가 많으면 브로커의 리소스 사용량도 증가
- 데이터양과 retention date(저장시간)을 고려하여 replication 설정이 필요함
- 3개의 브로커를 사용할 시에는 repliaction 3으로 설정하는 것을 추천

# Kafka Lag?

- 카프카 lag은 카프카 운영에 있어 중요한 모니터링 지표
- lag을 이해하려면

  - 토픽, 파티션, 컨슈머, 프로듀서, 오프셋에 대한 이해가 필요

- 오프셋?(offset)
  - 프로듀서에서 데이터를 토픽에 저장할 때, 개별 레코드에는 0부터 시작하는 오프셋이라는 숫자가 붙게됨
- 단일 파티션에서 컨슈머가 마지막으로 읽은 오프셋과 프로듀서가 마지막으로 넣은 오프셋의 차이를 lag이라고 함
- 오프셋의 차이를 통해 현재 컨슈머와 프로듀서간의 상태를 모니터링할 수 있는 지표로 사용할 수 있음
  - 주로 컨슈머의 상태를 확인하는데 사용함
- 파티션의 갯수만큼 lag도 생성될 수 있음
  - 파티션 중에서 가장 큰 lag을 `records-lag-max`으로 칭함
- 컨슈머의 입장에서 컨슈머의 성능이 저하된다고 생각될 때, lag은 반드시 발생하며 lag으로 모니터링할 수 있음

## `버로우(Burrow)`: kafka Lag 모니터링 오픈소스

- 실시간으로 lag을 모니터링하고자 한다면 elasticsearch나 influxDB와 같은 저장소에 넣은 후 grafana로 대시보드 확인 가능
- 컨슈머 단위에서 lag을 모니터링하는 것은 운영요소가 많이 필요함

  - 컨슈머 로직에서 lag 수집 -> 컨슈머 상태에 디펜던시
  - 컨슈머 비정상 종료시 컨슈머는 lag을 전송하지 못함
  - 컨슈머를 추가 개발할 때마다, 특정 저장소에 저장하는 로직을 추가개발해야함

- 따라서 컨슈머 lag을 효과적으로 모니터링할 수 있도록 링크드인에서 `버로우`를 개발

### 버로우 특징

- 멀티 카프카 클러스터를 지원
- \*슬라이딩 윈도우를 통한 컨슈머 상태 확인

  - `ERROR`, `WARNING`, `OK` 등 세가지 상태로 확인
  - `WARNING`: 데이터 양이 일시적으로 증가하여 오프셋이 증가하는 상태
  - `ERROR`: 데이터 양이 증가하지만, 컨슈머가 데이터가 가져지 않은 상태

- `HTTP API` 제공

  - 위의 정보를 HTTP API로 정보 제공
  - response 데이터를 시계열 DB에서 활용 가능

# rabbitMQ, redis, Kafka 차이!?

- 메시징 플랫폼들 간의 차이

## 메시지 플랫폼의 구분

- 메시징 플랫폼은 메시지 브로커, 이벤트 브로커 두 가지로 구분할 수 있음
- 메시지 브로커는 이벤트 브로커 역할이 불가능 하지만, 반대의 경우는 가능함

- 메시지 브로커

  - 메시지 기반 미들웨어 아키텍처에서 활용
  - 프로듀서, 컨슈머를 통해 메시지를 통신하고 네트워크를 맺는 역할
  - 메시지를 처리한 이후 즉시 또는 짧은 시간내에 삭제
  - Redis, rabbitMQ가 대표적

- 이벤트 브로커

  - 이벤트, 메시지의 레코드를 단일 보관하고 인덱스를 통해 개별 엑세스를 관리
  - 업무상 필요한 시간동안 이벤트를 보존
  - 즉, 메시지브로커는 데이터를 삭제하지만, 이벤트브로커는 삭제하지 않음
  - 서비스에서 나오는 이벤트를 데이터베이스에 저장하듯 큐에 저장
  - Kafka, AWS Kinesis가 대표적

### 이벤트 브로커(Kafka)

- 단일 이벤트 데이터를 브로커에 저장함으로써 단일 진실 공급원으로 사용
- 장애 발생시 장애 포인트부터 재처리가능
- 대규모 실시간 데이터를 효과적으로 처리
- 또한, 메시지 브로커로써 역할도 가능
- 그외 MSA에서 중요한 역할
